<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Notes on Machine Learning</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        background-color: #232629;
        color: #7a7c7d;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #7a7c7d;  padding-left: 4px; }
    div.sourceCode
      { color: #cfcfc2; background-color: #232629; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #cfcfc2; } /* Normal */
    code span.al { color: #95da4c; background-color: #4d1f24; font-weight: bold; } /* Alert */
    code span.an { color: #3f8058; } /* Annotation */
    code span.at { color: #2980b9; } /* Attribute */
    code span.bn { color: #f67400; } /* BaseN */
    code span.bu { color: #7f8c8d; } /* BuiltIn */
    code span.cf { color: #fdbc4b; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #3daee9; } /* Char */
    code span.cn { color: #27aeae; font-weight: bold; } /* Constant */
    code span.co { color: #7a7c7d; } /* Comment */
    code span.cv { color: #7f8c8d; } /* CommentVar */
    code span.do { color: #a43340; } /* Documentation */
    code span.dt { color: #2980b9; } /* DataType */
    code span.dv { color: #f67400; } /* DecVal */
    code span.er { color: #da4453; text-decoration: underline; } /* Error */
    code span.ex { color: #0099ff; font-weight: bold; } /* Extension */
    code span.fl { color: #f67400; } /* Float */
    code span.fu { color: #8e44ad; } /* Function */
    code span.im { color: #27ae60; } /* Import */
    code span.in { color: #c45b00; } /* Information */
    code span.kw { color: #cfcfc2; font-weight: bold; } /* Keyword */
    code span.op { color: #cfcfc2; } /* Operator */
    code span.ot { color: #27ae60; } /* Other */
    code span.pp { color: #27ae60; } /* Preprocessor */
    code span.re { color: #2980b9; background-color: #153042; } /* RegionMarker */
    code span.sc { color: #3daee9; } /* SpecialChar */
    code span.ss { color: #da4453; } /* SpecialString */
    code span.st { color: #f44f4f; } /* String */
    code span.va { color: #27aeae; } /* Variable */
    code span.vs { color: #da4453; } /* VerbatimString */
    code span.wa { color: #da4453; } /* Warning */
  </style>
  <link rel="stylesheet" href="./css/minimal.css" />
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Notes on Machine Learning</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#what-is-machine-learning">What is Machine Learning?</a></li>
<li><a href="#supervised-learning">Supervised Learning</a>
<ul>
<li><a href="#linear-regression">Linear Regression</a></li>
</ul></li>
</ul>
</nav>
<p><a href="index.html">Up one Page</a> | <a href="index.html">Back to ToC</a></p>
<p>Use this as a <strong>quick reference</strong>, in case you forget what’s what.</p>
<h2 id="what-is-machine-learning">What is Machine Learning?</h2>
<blockquote>
<p>Field of study that gives computers the ability to learn without being explicitly programmed</p>
<p>– Arthur Samuel (1959)</p>
</blockquote>
<blockquote>
<p>A computer program is said to <em>learn</em> from experience <strong>E</strong> with respect to some task <strong>T</strong> and some performance measure <strong>P</strong>, if its performance on <strong>T</strong>, as measured by <strong>P</strong>, improves with experience <strong>E</strong></p>
<p>– Tom Mitchell (1998)</p>
</blockquote>
<p>Thus for a spam classifier:</p>
<ul>
<li>Classifying emails as spam or not spam is the task <strong>T</strong></li>
<li>Labels for emails are the experience, <strong>E</strong></li>
<li>The fraction of correctly classified emails is the performance <strong>P</strong></li>
</ul>
<h2 id="supervised-learning">Supervised Learning</h2>
<h3 id="linear-regression">Linear Regression</h3>
<p>Given the “right answer” for each example in the data, predict real-valued output.</p>
<p>The optimization problem here is the following:</p>
<p><span class="math display">\[
\min_{\theta} \frac{1}{2m} \sum_{i = 1}^{m} \left[h(x^{(i)}; \theta) - y^{(i)}\right]^2
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(x^{(i)}\)</span> is the i-th training example</li>
<li><span class="math inline">\(h(\vec{x}; \theta) = \theta^T \vec{x}\)</span>, considering both as column vectors</li>
</ul>
<p>The way this is written, we are optimizing the squared error function over the training set.</p>
<p>The easiest way to do optimization the gradient descent method. Basically, move in the direction of <span class="math inline">\(-\nabla J\)</span> since that will be the direction of fastest <em>decrease</em>:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> (<span class="kw">not</span> converged) {</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="op">=</span> <span class="dv">1</span>:<span class="bu">len</span>(theta):</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        theta[j] <span class="op">=</span> theta[j] <span class="op">-</span> alpha <span class="op">*</span> J_grad(theta)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<h4 id="notation">Notation</h4>
<ul>
<li><span class="math inline">\(m\)</span>: <em>number of training examples</em></li>
<li><span class="math inline">\(\vec{x}\)</span>: vector of <em>“input” features</em></li>
<li><span class="math inline">\(\vec{y}\)</span>: vector of <em>“outputs” / targets</em>.</li>
<li><span class="math inline">\(\theta\)</span>: parameters which are to be learned. Usually a vector in this setting (WLOG, could be a matrix as well!)</li>
<li><span class="math inline">\(h(\vec{x}; \theta)\)</span>: hypothesis function. Along with <span class="math inline">\(\theta\)</span> and a (previously unseen) <span class="math inline">\(\vec{x}\)</span>, used to predict what will be the output of the machine learning algorithm given that input.</li>
<li><span class="math inline">\(\mathcal{J}\)</span>: Cost function. A proxy for the performance of the ML algorithm on the test set (stuff we haven’t ‘seen’ yet), defined as how badly the ML algorithm is performing on the training set (the data we are given for learning from).</li>
</ul>
</body>
</html>
